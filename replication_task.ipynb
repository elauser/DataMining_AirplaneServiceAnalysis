{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Proceedure short description\n",
    "\n",
    "Missing Data was replaced using median imputation.\n",
    "The text was cleaned of stop words and numbers, then the sentiment and emotion scores was mined through a lexicon based approach (NRC Word-Emotion Association Lexicon). The results were compared to an expert sampling which proved the correlation of both approaches.\n",
    "Attribute specific sentiments were mined through extracting all the through Ripple Down Rules-based Part-Of-Speech Tagging (RDRPOS) identified nouns which occurred in at least 5% of the dataset. The resulting 116 Nouns were put into “Bag of Words” created by 3 experts and 10 users of online reviews and airlines to identify the service attributes.\n",
    "Each sentence containing a word in a service attribute was matched with its sentiment score to create the final dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\"content\",\"cabin_flown\",\"overall_rating\",\"seat_comfort_rating\",\"cabin_staff_rating\",\"food_beverages_rating\",\"inflight_entertainment_rating\",\"value_money_rating\",\"recommended\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"airline_mean.csv\", encoding='latin1')\n",
    "df = df.iloc[:, 7:]\n",
    "df = df.drop(columns=['aircraft', 'type_traveller'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "With NRC Word-Emotion Association Lexicon (also called EmoLex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-1064a67034fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnrclex\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNRCLex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m df = df.merge(df.content.apply(lambda s: pd.Series(NRCLex(s).affect_frequencies)), \n\u001b[0m\u001b[0;32m      4\u001b[0m     left_index=True, right_index=True)\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4198\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4199\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4200\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-50-1064a67034fa>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnrclex\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNRCLex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m df = df.merge(df.content.apply(lambda s: pd.Series(NRCLex(s).affect_frequencies)), \n\u001b[0m\u001b[0;32m      4\u001b[0m     left_index=True, right_index=True)\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\nrclex.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mblob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mbuild_word_affect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mtop_emotions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\textblob\\decorators.py\u001b[0m in \u001b[0;36m__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\textblob\\blob.py\u001b[0m in \u001b[0;36msentences\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m         \u001b[1;34m\"\"\"Return list of :class:`Sentence <Sentence>` objects.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_sentence_objects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mcached_property\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\textblob\\blob.py\u001b[0m in \u001b[0;36m_create_sentence_objects\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    690\u001b[0m             \u001b[0mend_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart_index\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m             \u001b[1;31m# Sentences share the same models as their parent blob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 692\u001b[1;33m             s = Sentence(sent, start_index=start_index, end_index=end_index,\n\u001b[0m\u001b[0;32m    693\u001b[0m                 \u001b[0mtokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp_extractor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnp_extractor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m                 \u001b[0mpos_tagger\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_tagger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\textblob\\blob.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sentence, start_index, end_index, *args, **kwargs)\u001b[0m\n\u001b[0;32m    710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 712\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSentence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    713\u001b[0m         \u001b[1;31m#: The start index within a TextBlob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\textblob\\blob.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, text, tokenizer, pos_tagger, np_extractor, analyzer, parser, classifier, clean_html)\u001b[0m\n\u001b[0;32m    374\u001b[0m                                     \"get_text() function\")\n\u001b[0;32m    375\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstripped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlowerstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m         _initialize_models(self, tokenizer, pos_tagger, np_extractor, analyzer,\n\u001b[0;32m    378\u001b[0m                            parser, classifier)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from nrclex import NRCLex\n",
    "\n",
    "df = df.merge(df.content.apply(lambda s: pd.Series(NRCLex(s).affect_frequencies)), \n",
    "    left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Sentiment\n",
    "= positive - negative / positive + negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['overall_sentiment'] = (df.positive - df.negative)/(df.positive + df.negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words to find service attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "services = {}\n",
    "services['punctuality_sm'] = ['time', 'hour', 'boarding', 'minutes', 'delay', 'day' 'arrival','departure']\n",
    "services['food_bev_sm'] = 'Food, meal, drinks, water, breakfast'.lower().split(', ')\n",
    "services['comfort_sm'] = 'Seat, cabin, leg, lounge, room, legroom, seating, row, landing, sleep, space'.lower().split(', ')\n",
    "services['staff_bh_sm'] = 'Crew, staff, attendants, people, ground'.lower().split(', ')\n",
    "services['inflight_ent_sm'] = 'Entertainment, experience, inflight, movies'.lower().split(', ')\n",
    "services['checkin_sm'] = 'Check in, luggage, board, baggage'.lower().split(', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "We go through each review, split it into its composing sentences and see if it contains words from the services defined previously. We combine the sentences by averaging the sentiment scores for each category and in the end fill the missing values with the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>cabin_flown</th>\n",
       "      <th>overall_rating</th>\n",
       "      <th>seat_comfort_rating</th>\n",
       "      <th>cabin_staff_rating</th>\n",
       "      <th>food_beverages_rating</th>\n",
       "      <th>inflight_entertainment_rating</th>\n",
       "      <th>value_money_rating</th>\n",
       "      <th>recommended</th>\n",
       "      <th>fear</th>\n",
       "      <th>...</th>\n",
       "      <th>sadness</th>\n",
       "      <th>disgust</th>\n",
       "      <th>joy</th>\n",
       "      <th>overall_sentiment</th>\n",
       "      <th>food_bev_sm</th>\n",
       "      <th>punctuality_sm</th>\n",
       "      <th>comfort_sm</th>\n",
       "      <th>staff_bh_sm</th>\n",
       "      <th>checkin_sm</th>\n",
       "      <th>inflight_ent_sm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Outbound flight FRA/PRN A319. 2 hours 10 min f...</td>\n",
       "      <td>Economy</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.101604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101604</td>\n",
       "      <td>0.096257</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>-0.027027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067703</td>\n",
       "      <td>0.031233</td>\n",
       "      <td>0.099550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Two short hops ZRH-LJU and LJU-VIE. Very fast ...</td>\n",
       "      <td>Business Class</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089744</td>\n",
       "      <td>0.089744</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.107043</td>\n",
       "      <td>0.020541</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.031233</td>\n",
       "      <td>0.099550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flew Zurich-Ljubljana on JP365 newish CRJ900. ...</td>\n",
       "      <td>Economy</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.090226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.090226</td>\n",
       "      <td>0.097744</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048736</td>\n",
       "      <td>0.067703</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adria serves this 100 min flight from Ljubljan...</td>\n",
       "      <td>Business Class</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.093023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087209</td>\n",
       "      <td>0.087209</td>\n",
       "      <td>0.093023</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020541</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.067703</td>\n",
       "      <td>0.031233</td>\n",
       "      <td>0.099550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WAW-SKJ Economy. No free snacks or drinks on t...</td>\n",
       "      <td>Economy</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.098266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095376</td>\n",
       "      <td>0.089595</td>\n",
       "      <td>0.095376</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.020541</td>\n",
       "      <td>0.048736</td>\n",
       "      <td>0.067703</td>\n",
       "      <td>0.031233</td>\n",
       "      <td>0.099550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sarajevo-Frankfurt via Ljubljana. I loved flyi...</td>\n",
       "      <td>Economy</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.097046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092827</td>\n",
       "      <td>0.092827</td>\n",
       "      <td>0.101266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107043</td>\n",
       "      <td>0.020541</td>\n",
       "      <td>0.048736</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I had flights from Paris to Sarajevo via Ljubl...</td>\n",
       "      <td>Economy</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.097701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097701</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>0.097701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.020541</td>\n",
       "      <td>0.048736</td>\n",
       "      <td>0.067703</td>\n",
       "      <td>0.031233</td>\n",
       "      <td>0.099550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LJU to FRA and back both flights were on time....</td>\n",
       "      <td>Economy</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097826</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.097826</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.107043</td>\n",
       "      <td>0.020541</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.031233</td>\n",
       "      <td>0.099550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>On my Ljubljana - Munich flight in business cl...</td>\n",
       "      <td>Business Class</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097179</td>\n",
       "      <td>0.094044</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>-0.014925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020541</td>\n",
       "      <td>0.048736</td>\n",
       "      <td>0.067703</td>\n",
       "      <td>0.031233</td>\n",
       "      <td>0.099550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Flights from LJU to ZRH and back all on time. ...</td>\n",
       "      <td>Economy</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.084615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092308</td>\n",
       "      <td>0.084615</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.031233</td>\n",
       "      <td>0.099550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content     cabin_flown  \\\n",
       "0  Outbound flight FRA/PRN A319. 2 hours 10 min f...         Economy   \n",
       "1  Two short hops ZRH-LJU and LJU-VIE. Very fast ...  Business Class   \n",
       "2  Flew Zurich-Ljubljana on JP365 newish CRJ900. ...         Economy   \n",
       "3  Adria serves this 100 min flight from Ljubljan...  Business Class   \n",
       "4  WAW-SKJ Economy. No free snacks or drinks on t...         Economy   \n",
       "5  Sarajevo-Frankfurt via Ljubljana. I loved flyi...         Economy   \n",
       "6  I had flights from Paris to Sarajevo via Ljubl...         Economy   \n",
       "7  LJU to FRA and back both flights were on time....         Economy   \n",
       "8  On my Ljubljana - Munich flight in business cl...  Business Class   \n",
       "9  Flights from LJU to ZRH and back all on time. ...         Economy   \n",
       "\n",
       "   overall_rating  seat_comfort_rating  cabin_staff_rating  \\\n",
       "0               7                    4                   4   \n",
       "1              10                    4                   5   \n",
       "2               9                    5                   5   \n",
       "3               8                    4                   4   \n",
       "4               4                    4                   2   \n",
       "5               9                    4                   4   \n",
       "6               5                    4                   4   \n",
       "7               9                    5                   5   \n",
       "8               8                    4                   3   \n",
       "9              10                    5                   5   \n",
       "\n",
       "   food_beverages_rating  inflight_entertainment_rating  value_money_rating  \\\n",
       "0                      4                              2                   4   \n",
       "1                      4                              1                   5   \n",
       "2                      4                              2                   5   \n",
       "3                      3                              1                   4   \n",
       "4                      1                              2                   2   \n",
       "5                      3                              3                   4   \n",
       "6                      1                              2                   3   \n",
       "7                      4                              3                   4   \n",
       "8                      4                              1                   4   \n",
       "9                      4                              4                   4   \n",
       "\n",
       "   recommended      fear  ...   sadness   disgust       joy  \\\n",
       "0            1  0.101604  ...  0.101604  0.096257  0.090909   \n",
       "1            1  0.102564  ...  0.089744  0.089744  0.102564   \n",
       "2            1  0.090226  ...  0.105263  0.090226  0.097744   \n",
       "3            1  0.093023  ...  0.087209  0.087209  0.093023   \n",
       "4            0  0.098266  ...  0.095376  0.089595  0.095376   \n",
       "5            1  0.097046  ...  0.092827  0.092827  0.101266   \n",
       "6            1  0.097701  ...  0.097701  0.086207  0.097701   \n",
       "7            1  0.086957  ...  0.097826  0.086957  0.097826   \n",
       "8            1  0.103448  ...  0.097179  0.094044  0.103448   \n",
       "9            1  0.084615  ...  0.092308  0.084615  0.100000   \n",
       "\n",
       "   overall_sentiment  food_bev_sm  punctuality_sm  comfort_sm  staff_bh_sm  \\\n",
       "0          -0.027027     0.000000        0.000000    0.000000     0.067703   \n",
       "1           0.058824     0.107043        0.020541    0.000000     0.100000   \n",
       "2           0.030303     0.090909        0.000000    0.048736     0.067703   \n",
       "3           0.121951     0.000000        0.020541    0.058824     0.067703   \n",
       "4           0.051282     0.033333        0.020541    0.048736     0.067703   \n",
       "5           0.000000     0.107043        0.020541    0.048736     0.090909   \n",
       "6           0.000000     0.250000        0.020541    0.048736     0.067703   \n",
       "7           0.142857     0.107043        0.020541    0.200000     0.200000   \n",
       "8          -0.014925     0.000000        0.020541    0.048736     0.067703   \n",
       "9           0.161290     0.066667        0.066667    0.266667     0.333333   \n",
       "\n",
       "   checkin_sm  inflight_ent_sm  \n",
       "0    0.031233         0.099550  \n",
       "1    0.031233         0.099550  \n",
       "2    0.000000         0.099550  \n",
       "3    0.031233         0.099550  \n",
       "4    0.031233         0.099550  \n",
       "5    0.090909         0.090909  \n",
       "6    0.031233         0.099550  \n",
       "7    0.031233         0.099550  \n",
       "8    0.031233         0.099550  \n",
       "9    0.031233         0.099550  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_sentiment_service(text):\n",
    "    service_sentiments = service_osm_list(text)\n",
    "    sm = pd.DataFrame(service_sentiments)\n",
    "    answer = sm.mean()\n",
    "    return answer\n",
    "    \n",
    "def service_osm_list(text):\n",
    "    sentences = NRCLex(text).sentences\n",
    "    sentiments = []\n",
    "    for sentence in sentences:\n",
    "        sentence = str(sentence)\n",
    "        result = {}\n",
    "        osm = overall_sentiment_in_text(sentence)\n",
    "        srvc = services_in_sentence(sentence)\n",
    "        for service in srvc:\n",
    "            result[service] = osm\n",
    "        sentiments.append(result)\n",
    "    return sentiments\n",
    "\n",
    "def overall_sentiment_in_text(text):\n",
    "    sentiment = NRCLex(text).affect_frequencies\n",
    "    try:\n",
    "        overall_sentiment = (sentiment['positive'] - sentiment['negative'])/(sentiment['positive'] + sentiment['negative'])\n",
    "        return overall_sentiment\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "\n",
    "def services_in_sentence(sentence):\n",
    "    words = sentence.lower().split()\n",
    "    srv = set()\n",
    "    for key, value in services.items():\n",
    "        if any(item in words for item in value):\n",
    "            srv.add(key)\n",
    "    return srv\n",
    "\n",
    "df_final = df.merge(df.content.apply(extract_sentiment_service), \n",
    "    left_index=True, right_index=True)\n",
    "\n",
    "# Missing Fields were filled with the mean\n",
    "df_final = df_final.fillna(df_final.mean())\n",
    "df_final.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.drop(columns=['content']).to_csv('final_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
